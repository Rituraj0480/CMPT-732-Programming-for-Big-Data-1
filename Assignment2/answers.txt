Answer 1: [ Q: In the WikipediaPopular class, it would be much more interesting to find the page that is most popular, not just the view count (as we did with Spark). What would be necessary to modify your class to do this? ]

Instead of sending just the Views as Int value, we have to send the mapper output as tuple - where 1st is Views and 2nd is Title (Eg: context.write(word, views) - views be converted from LongWritable to tuple of LongPairWritable).

Similarly in Reducer, we have to calculate maximum Views & its corresponding Title (in For Loop) and send it in tuple as LongPairWritable format.




Answer 2: [ Q: An RDD has many methods: it can do many more useful tricks than were at hand with MapReduce. Write a sentence or two to explain the difference between .map and .flatMap. Which is more like the MapReduce concept of mapping? ]

.map() returns the transformed dataset by passing each element of the source dataset through the function. .flatmap is similar to .map, but it can also return multiple items for each element in source dataset. .flatmap flattens the outputs after applying the given function. .flatmap is one-to-many transformation function. Therefore, .map() always return the same size of records as in the input Dataset, whereas .flatMap() returns many records for each record.

According to me, .flatmap() is more like MapReduce concept of mapping.




Answer 3: [ Q:Do the same for .reduce and .reduceByKey. Which is more like the MapReduce concept of reducing? ]

The Reduce() combines the elements of the dataset using the given function. It takes two arguments from source file and returns one. The .ReduceByKey() returns (Key, Value) pairs, where the values for each key are aggregated using the given reduce function. The output of .reduceByKey() is a RDD.

I think .reduceByKey() is more like a reducer in MapReduce.




Answer 4: [ Q: When finding popular Wikipedia pages, the maximum number of page views is certainly unique, but the most popular page might be a tie. What would your improved Python implementation do if there were two pages with the same highest number of page views in an hour? What would be necessary to make your code find all of the pages views the maximum number of times? ]

If there are two or more pages with the same highest number of views in an hour, then I will return the title of both/all these pages and their views. Below is the logic for my code:

X = ('datetime', (170, 'Page1'))
Y = ('datetime', (170, 'Page2'))

I will change the reduceByKey() method as below:

# I have included elif/else if in the new code below.


def maximum(x, y):
	if x[0]>y[0]:
		return x

	elif x[0]==y[0]:
		new_view = x[0]
		new_title = x[1] + ' and ' + y[1]
		return (new_view, new_title)

	else:
		return y


The Final Output will be: ('datetime', (170, 'Page1 and Page2'))

Note: This is my initial thought of keeping views as same, and adding both the pages title into one title. I can later modify this code to return output in some other formats.